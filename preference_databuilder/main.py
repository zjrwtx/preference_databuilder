
"""
å¾®ä¿¡å…¬ä¼—å·ï¼šæ­£ç»äººç‹åŒå­¦

"""
import os
import random
import numpy as np
import pandas as pd
import streamlit as st

import json
from openai import OpenAI

from dotenv import load_dotenv
# åœ¨ä½¿ç”¨APIå¯†é’¥å’ŒåŸºç¡€URLä¹‹å‰åŠ è½½.envæ–‡ä»¶
load_dotenv()

# ç°åœ¨å¯ä»¥é€šè¿‡os.environè®¿é—®è¿™äº›å€¼
API_BASE = os.environ.get("API_BASE")
API_KEY = os.environ.get("API_KEY")


client = OpenAI(
    # defaults to os.environ.get("OPENAI_API_KEY")
    api_key="dbe000b3e7f44df98d6c3f330cccf5a1",
    base_url="http://localhost:11434/v1/"
    
    # base_url="https://api.lingyiwanwu.com/v1/"
)







st.set_page_config(
    page_title="PPOè®­ç»ƒåå¥½æ•°æ®æ’åºåŠ©æ‰‹",
    page_icon='',
    layout="wide"
)

MODEL_CONFIG = {
    'model_name': '',             # backbone
    'dataset_file': 'total_dataset.json',       # æ ‡æ³¨æ•°æ®é›†çš„å­˜æ”¾æ–‡ä»¶
    'rank_list_len': 4,                                           # æ’åºåˆ—è¡¨çš„é•¿åº¦
    'max_gen_seq_len': 1000,                                        # ç”Ÿæˆç­”æ¡ˆæœ€å¤§é•¿åº¦
    'random_prompts': [                                           # éšæœºpromptæ± 
                        'ä¸€èµ·å»åƒä¸ªé¥­å—',
                        'ä½ çœŸå¥½çœ‹',
                        'ä½ å¹²å˜›è¿™ä¹ˆå”¯å”¯è¯ºè¯º',
                        'å–œæ¬¢åƒæ¨æç”˜éœ²ä¸',
                        'è·Ÿæˆ‘è¯´è¯´rustçš„åº”ç”¨åœºæ™¯å§',
                        'äººç”Ÿçš„æ„ä¹‰æ˜¯ä»€ä¹ˆ'
                    ]
}


######################## é¡µé¢é…ç½®åˆå§‹åŒ– ###########################
RANK_COLOR = [
    'red',
    'green',
    'blue',
    'orange',
    'violet'
]


######################## ä¼šè¯ç¼“å­˜åˆå§‹åŒ– ###########################
if 'model_config' not in st.session_state:
    st.session_state['model_config'] = MODEL_CONFIG

if 'current_results' not in st.session_state:
    st.session_state['current_results'] = [''] * MODEL_CONFIG['rank_list_len']

if 'current_prompt' not in st.session_state:
    st.session_state['current_prompt'] = 'å–œæ¬¢åƒæ¨æç”˜éœ²ä¸'

def predict(input):
  completion = client.chat.completions.create(
        model="qwen:0.5b",
        messages=[{"role": "user", "content":input}],
        max_tokens=1000,
        # stream=True,
    )
  response=completion.choices[0].message.content
  with st.empty():
        st.write(input) 
        st.write("AIæ­£åœ¨å›å¤:")
        st.write(response)
  return  response


######################### å‡½æ•°å®šä¹‰åŒº ##############################

def generate_text():
    current_results = []

    for _ in range(MODEL_CONFIG['rank_list_len']):

        # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
        if 'interrupt_flag' in st.session_state and st.session_state['interrupt_flag']:
            st.session_state['interrupt_flag'] = False  # æ¸…é™¤ä¸­æ–­æ ‡å¿—
            break

        # ç”Ÿæˆæ–‡æœ¬
        result  = predict(st.session_state['current_prompt'])
       
        generated_text = result
        print(generated_text)
        # æ·»åŠ åˆ°åˆ—è¡¨ä¸­
        if len(generated_text) > MODEL_CONFIG['max_gen_seq_len']:
            generated_text = generated_text[:MODEL_CONFIG['max_gen_seq_len']]
        current_results.append(generated_text)
        
        
        if len(current_results) == MODEL_CONFIG['rank_list_len']:
            break  # åˆ—è¡¨é•¿åº¦å·²è¾¾åˆ°æœ€å¤§å€¼ï¼Œè·³å‡ºå¾ªç¯
    
    st.session_state['current_results'] = current_results

    return current_results


# å­˜å‚¨å½“å‰æ’åºåˆ°jsonæ–‡ä»¶ä¸­
def save_to_json(data):
    with open(MODEL_CONFIG["dataset_file"], "a", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False)
        f.write("\n")

# ä»jsonæ–‡ä»¶ä¸­è¯»å–ä¹‹å‰æ ‡æ³¨è¿‡çš„æ•°æ®é›†
def read_from_json():
    rank_texts_list = []
    if not os.path.exists(MODEL_CONFIG["dataset_file"]):
        st.warning("æš‚æ— æ•°æ®ï¼Œè¯·å¼€å§‹æ ‡æ³¨")
    else:
        with open(MODEL_CONFIG["dataset_file"], "r", encoding="utf-8") as f:
            for line in f.readlines():
                data = json.loads(line.strip())
                rank_texts_list.append(data)
    return rank_texts_list
######################### é¡µé¢å®šä¹‰åŒºï¼ˆä¾§è¾¹æ ï¼‰ ########################
st.sidebar.title('å¤§æ¨¡å‹RLHFï¼ˆppoå¥–åŠ±æ¨¡å‹ï¼‰è®­ç»ƒåå¥½æ•°æ®æ’åºåŠ©æ‰‹ï¼ˆollamaæœ¬åœ°æ¨¡å‹ç‰ˆï¼‰')
# st.sidebar.markdown('''
#     ```
#                     
#     ```
# ''')
st.sidebar.markdown('''
    
                    ç®€å•æ¥è¯´å°±æ˜¯ä½ ç»è¿‡sftå¾®è°ƒåï¼Œæƒ³é€šè¿‡RLHFï¼ˆppoå¥–åŠ±æ¨¡å‹ï¼‰è®­ç»ƒæ€ä¹ˆæ ·çš„æ¨¡å‹ï¼Œå°±ç»™ä½ çš„æ¨¡å‹ç”Ÿæˆå›ç­”è¿›è¡Œæ’åºï¼Œæœ€åå†å¯¼å‡ºåå¥½æ•°æ®å»è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œå†ç”¨å¥–åŠ±æ¨¡å‹å»è®­ç»ƒsftæ¨¡å‹
                    
                    1ã€ç›®å‰å·²æ”¯æŒollamaæœ¬åœ°æ¨¡å‹ï¼Œç”Ÿæˆçš„æ’åºä¸ªæ•°ç­‰å‚æ•°éƒ½å¯ä»¥ç›´æ¥åœ¨ä»£ç æ”¹

                    2ã€ç®€å•æ”¹ä¸€ä¸‹ä»£ç å°±æ”¯æŒOpenaiæ¨¡å‹ apiå¼çš„äº‘ç«¯æ¨¡å‹å•¦

                    3ã€åœ¨ç ”ç©¶ä¸€ä¸ªå¾ˆcoolçš„åŠŸèƒ½ï¼Œè®©å¤§æ¨¡å‹è‡ªå·±ç»™è‡ªå·±æ’åºï¼Œè‡ªå·±å¥–åŠ±è‡ªå·±......
''')
st.sidebar.markdown('æœ¬é¡¹ç›®å¼€æºåœ¨[github](https://github.com/zjrwtx/preference_databuilder) ã€‚')

st.sidebar.markdown('[å¾®ä¿¡å…¬ä¼—å·ï¼šæ­£ç»äººç‹åŒå­¦](https://mp.weixin.qq.com/s/t3zAsWZ3djokWEjboaDkmQ) ã€‚')

label_tab, dataset_tab = st.tabs(['Label', 'Dataset'])


######################### é¡µé¢å®šä¹‰åŒºï¼ˆæ ‡æ³¨é¡µé¢ï¼‰ ########################
with label_tab:
    with st.expander('ğŸ’¡è®¾ç½®ä¸€ä¸‹prompt', expanded=True):
        random_button = st.button('éšæœº prompt',
                                  help='ä»promptæ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªpromptï¼Œå¯é€šè¿‡ä¿®æ”¹æºç ä¸­ MODEL_CONFIG["random_prompts"] å‚æ•°æ¥è‡ªå®šä¹‰promptæ± ã€‚')
        if random_button:
            prompt_text = random.choice(MODEL_CONFIG['random_prompts'])
        else:
            prompt_text = st.session_state.get('current_prompt', '')

        query_txt = st.text_input('prompt: ', prompt_text)
        if query_txt != st.session_state.get('current_prompt', ''):
            st.session_state['current_prompt'] = query_txt
            generate_text()

        interrupt_button = st.button('ä¸­æ–­è¾“å‡º', key='interrupt_button', help='æŒ‰ä¸‹ä¸­æ–­è¾“å‡ºæŒ‰é’®å¯ä¸­æ–­ç”Ÿæˆç­”æ¡ˆçš„æ“ä½œã€‚')
        if interrupt_button:
            st.session_state['interrupt_flag'] = True

        generate_button = st.button('ç”Ÿæˆç»“æœ', key='generate_button', help='æŒ‰ä¸‹ Enter é”®æ¥ç”Ÿæˆç»“æœã€‚')
        if generate_button:
            generate_text()

    with st.expander('ğŸ’¡ Generate Results', expanded=True):
        columns = st.columns([1] * MODEL_CONFIG['rank_list_len'])
        rank_results = [-1] * MODEL_CONFIG['rank_list_len']
        rank_choices = [-1] + [i + 1 for i in range(MODEL_CONFIG['rank_list_len'])]
        for i, c in enumerate(columns):
            with c:
                choice = st.selectbox(f'å¥å­{i + 1}æ’å', rank_choices,
                                      help='ä¸ºå½“å‰å¥å­é€‰æ‹©æ’åï¼Œæ’åè¶Šå°ï¼Œå¾—åˆ†è¶Šé«˜ã€‚ï¼ˆ-1ä»£è¡¨å½“å‰å¥å­æš‚æœªè®¾ç½®æ’åï¼‰')
                if choice != -1 and choice in rank_results:
                    st.info(
                        f'å½“å‰æ’å[{choice}]å·²ç»è¢«å¥å­[{rank_results.index(choice) + 1}]å ç”¨ï¼Œè¯·å…ˆå°†å ç”¨æ’åçš„å¥å­ç½®ä¸º-1å†ä¸ºå½“å‰å¥å­åˆ†é…è¯¥æ’åã€‚')
                else:
                    rank_results[i] = choice
                color = RANK_COLOR[i] if i < len(RANK_COLOR) else 'white'
                current_results = st.session_state.get('current_results', [])
                if i < len(current_results):
                    text = current_results[i]
                else:
                    text = ''

                st.markdown(f":{color}[{text}]")

    with st.expander('ğŸ¥‡ Rank Results', expanded=True):
        columns = st.columns([1] * MODEL_CONFIG['rank_list_len'])
        for i, c in enumerate(columns):
            with c:
                st.write(f'Rank {i+1}ï¼š')
                if i + 1 in rank_results:
                    color = RANK_COLOR[rank_results.index(i+1)] if rank_results.index(i+1) < len(RANK_COLOR) else 'white'
                    st.markdown(f":{color}[{st.session_state['current_results'][rank_results.index(i+1)]}]")

    # æ›¿æ¢é¡µé¢å®šä¹‰åŒºæ ‡æ³¨é¡µé¢ä¸­çš„æ•°æ®è¯»å–æ–¹å¼å’Œä¿å­˜æ–¹å¼
    save_button = st.button('å­˜å‚¨å½“å‰æ’åº')
    if save_button:
        if -1 in rank_results:
            st.error('è¯·å®Œæˆæ’åºåå†å­˜å‚¨ï¼', icon='ğŸš¨')
            st.stop()

        prompt_text = st.session_state['current_prompt']
        data = {"prompt": prompt_text}
        for i in range(len(rank_results)):
            data[f'rank_{i + 1}'] = st.session_state['current_results'][rank_results.index(i + 1)]
        save_to_json(data)

        st.success('ä¿å­˜æˆåŠŸï¼Œè¯·æ›´æ¢promptç”Ÿæˆæ–°çš„ç­”æ¡ˆ~', icon="âœ…")

######################### é¡µé¢å®šä¹‰åŒºï¼ˆæ•°æ®é›†é¡µé¢ï¼‰ #######################
# æ›¿æ¢é¡µé¢å®šä¹‰åŒºæ•°æ®é›†é¡µé¢ä¸­çš„æ•°æ®è¯»å–æ–¹å¼
with dataset_tab:
# è¯»å–æ•°æ®å¹¶åˆ›å»º DataFrame ç¤ºä¾‹
    rank_texts_list = read_from_json()
    df = pd.DataFrame(rank_texts_list)

    # åœ¨ Streamlit ç•Œé¢ä¸­æ˜¾ç¤ºå¯ç¼–è¾‘è¡¨æ ¼
    edited_df = st.data_editor(df)

# å¢åŠ ä¿å­˜æŒ‰é’®
    if st.button('ä¿å­˜æ›´æ”¹'):
        # å°†ç¼–è¾‘åçš„ DataFrame è½¬æ¢ä¸º list æ ¼å¼
        updated_data = edited_df.to_dict('records')

        with open(MODEL_CONFIG["dataset_file"], "w", encoding="utf-8") as f:
            for data in updated_data:
                json.dump(data, f, ensure_ascii=False)
                f.write("\n")

    st.success('ä¿å­˜æˆåŠŸï¼')

