
"""
è¿™æ˜¯æ³¨é‡Š
"""
import os
import random
import numpy as np
import pandas as pd
import streamlit as st
from transformers import (
    AutoModel,
    AutoTokenizer,

)
import json
from openai import OpenAI

from dotenv import load_dotenv
# åœ¨ä½¿ç”¨APIå¯†é’¥å’ŒåŸºç¡€URLä¹‹å‰åŠ è½½.envæ–‡ä»¶
load_dotenv()

# ç°åœ¨å¯ä»¥é€šè¿‡os.environè®¿é—®è¿™äº›å€¼
API_BASE = os.environ.get("API_BASE")
API_KEY = os.environ.get("API_KEY")


client = OpenAI(
    # defaults to os.environ.get("OPENAI_API_KEY")
    api_key=API_KEY,
    base_url=API_BASE
)







st.set_page_config(
    page_title="Rank List Labeler",
    page_icon='ğŸ“Œ',
    layout="wide"
)

MODEL_CONFIG = {
    'model_name': 'THUDM/chatglm-6b-int4',             # backbone
    'dataset_file': 'total_dataset.json',       # æ ‡æ³¨æ•°æ®é›†çš„å­˜æ”¾æ–‡ä»¶
    'rank_list_len': 6,                                           # æ’åºåˆ—è¡¨çš„é•¿åº¦
    'max_gen_seq_len': 1000,                                        # ç”Ÿæˆç­”æ¡ˆæœ€å¤§é•¿åº¦
    'random_prompts': [                                           # éšæœºpromptæ± 
                        'ä»Šå¤©æˆ‘å»äº†',
                        'è¿™éƒ¨ç”µå½±å¾ˆ',
                        'åˆšæ”¶åˆ°è´§ï¼Œæ„Ÿè§‰',
                        'è¿™éƒ¨ç”µå½±å¾ˆ',
                        'è¯´å®è¯ï¼ŒçœŸçš„å¾ˆ',
                        'è¿™æ¬¡è´­ç‰©æ€»çš„æ¥è¯´ä½“éªŒå¾ˆ'
                    ]
}


######################## é¡µé¢é…ç½®åˆå§‹åŒ– ###########################
RANK_COLOR = [
    'red',
    'green',
    'blue',
    'orange',
    'violet'
]


######################## ä¼šè¯ç¼“å­˜åˆå§‹åŒ– ###########################
if 'model_config' not in st.session_state:
    st.session_state['model_config'] = MODEL_CONFIG

@st.cache_resource()



def predict(input, history=None):
    completion = client.chat.completions.create(
    model="yi-34b-chat-200k",
    messages=[{"role": "user", "content":input}],
    max_tokens=6000,
    top_p=0.8,
    # stream=True,
)
    outputtext=completion.choices[0].message.content
    print(outputtext)
    with st.empty():
        st.write(input) # å°† message å‡½æ•°æ”¹æˆäº† st.write
        st.write("AIæ­£åœ¨å›å¤:")
        for response, history in model.stream_chat(tokenizer, input, history):
            query, response = history[-1]
            st.write(response)
        return response



if 'current_results' not in st.session_state:
    st.session_state['current_results'] = [''] * MODEL_CONFIG['rank_list_len']

if 'current_prompt' not in st.session_state:
    st.session_state['current_prompt'] = 'ä»Šå¤©æ—©æ™¨æˆ‘å»äº†'


######################### å‡½æ•°å®šä¹‰åŒº ##############################

def generate_text():
    current_results = []
    for _ in range(MODEL_CONFIG['rank_list_len']):

        # æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
        if 'interrupt_flag' in st.session_state and st.session_state['interrupt_flag']:
            st.session_state['interrupt_flag'] = False  # æ¸…é™¤ä¸­æ–­æ ‡å¿—
            break

        # ç”Ÿæˆæ–‡æœ¬
        result = predict(st.session_state['current_prompt'])
        generated_text = result
        if len(generated_text) > MODEL_CONFIG['max_gen_seq_len']:
            generated_text = generated_text[:MODEL_CONFIG['max_gen_seq_len']]
        current_results.append(generated_text)
        if len(current_results) == MODEL_CONFIG['rank_list_len']:
            break  # åˆ—è¡¨é•¿åº¦å·²è¾¾åˆ°æœ€å¤§å€¼ï¼Œè·³å‡ºå¾ªç¯
    st.session_state['current_results'] = current_results
    print(current_results)
    return current_results


# å­˜å‚¨å½“å‰æ’åºåˆ°jsonæ–‡ä»¶ä¸­
def save_to_json(data):
    with open(MODEL_CONFIG["dataset_file"], "a", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False)
        f.write("\n")

# ä»jsonæ–‡ä»¶ä¸­è¯»å–ä¹‹å‰æ ‡æ³¨è¿‡çš„æ•°æ®é›†
def read_from_json():
    rank_texts_list = []
    if not os.path.exists(MODEL_CONFIG["dataset_file"]):
        st.warning("æš‚æ— æ•°æ®ï¼Œè¯·å¼€å§‹æ ‡æ³¨")
    else:
        with open(MODEL_CONFIG["dataset_file"], "r", encoding="utf-8") as f:
            for line in f.readlines():
                data = json.loads(line.strip())
                rank_texts_list.append(data)
    return rank_texts_list
######################### é¡µé¢å®šä¹‰åŒºï¼ˆä¾§è¾¹æ ï¼‰ ########################
st.sidebar.title('è®©Yiå¤§æ¨¡å‹è‡ªåŠ¨ç»™äºˆè®­ç»ƒæ¨¡å‹çš„ç”Ÿæˆè¿›è¡Œæ’åº')
# st.sidebar.markdown('''
#     ```
#                     
#     ```
# ''')
st.sidebar.markdown('''
    
                    ç®€å•æ¥è¯´å°±æ˜¯ä½ ç»è¿‡sftå¾®è°ƒåï¼Œæƒ³é€šè¿‡RLHFï¼ˆppoå¥–åŠ±æ¨¡å‹ï¼‰è®­ç»ƒæ€ä¹ˆæ ·çš„æ¨¡å‹ï¼Œå°±è®©Yiå¤§æ¨¡å‹è‡ªåŠ¨ç»™ä½ çš„æ¨¡å‹ç”Ÿæˆå›ç­”è¿›è¡Œæ’åºï¼Œæœ€åå†å¯¼å‡ºåå¥½æ•°æ®å»è®­ç»ƒå¥–åŠ±æ¨¡å‹ã€‚
    
''')
st.sidebar.markdown('æœ¬é¡¹ç›®å¼€æºåœ¨[github](https://arxiv.org/pdf/2203.02155.pdf) ã€‚')


label_tab, dataset_tab = st.tabs(['Label', 'Dataset'])


######################### é¡µé¢å®šä¹‰åŒºï¼ˆæ ‡æ³¨é¡µé¢ï¼‰ ########################
with label_tab:
    with st.expander('ğŸ” Setting Prompts', expanded=True):
        random_button = st.button('éšæœº prompt',
                                  help='ä»promptæ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªpromptï¼Œå¯é€šè¿‡ä¿®æ”¹æºç ä¸­ MODEL_CONFIG["random_prompts"] å‚æ•°æ¥è‡ªå®šä¹‰promptæ± ã€‚')
        if random_button:
            prompt_text = random.choice(MODEL_CONFIG['random_prompts'])
        else:
            prompt_text = st.session_state.get('current_prompt', '')

        query_txt = st.text_input('prompt: ', prompt_text)
        if query_txt != st.session_state.get('current_prompt', ''):
            st.session_state['current_prompt'] = query_txt
            generate_text()

        interrupt_button = st.button('ä¸­æ–­è¾“å‡º', key='interrupt_button', help='æŒ‰ä¸‹ä¸­æ–­è¾“å‡ºæŒ‰é’®å¯ä¸­æ–­ç”Ÿæˆç­”æ¡ˆçš„æ“ä½œã€‚')
        if interrupt_button:
            st.session_state['interrupt_flag'] = True

        generate_button = st.button('ç”Ÿæˆç»“æœ', key='generate_button', help='æŒ‰ä¸‹ Enter é”®æ¥ç”Ÿæˆç»“æœã€‚')
        if generate_button:
            generate_text()

    with st.expander('ğŸ’¡ Generate Results', expanded=True):
        columns = st.columns([1] * MODEL_CONFIG['rank_list_len'])
        rank_results = [-1] * MODEL_CONFIG['rank_list_len']
        rank_choices = [-1] + [i + 1 for i in range(MODEL_CONFIG['rank_list_len'])]
        for i, c in enumerate(columns):
            with c:
                choice = st.selectbox(f'å¥å­{i + 1}æ’å', rank_choices,
                                      help='ä¸ºå½“å‰å¥å­é€‰æ‹©æ’åï¼Œæ’åè¶Šå°ï¼Œå¾—åˆ†è¶Šé«˜ã€‚ï¼ˆ-1ä»£è¡¨å½“å‰å¥å­æš‚æœªè®¾ç½®æ’åï¼‰')
                if choice != -1 and choice in rank_results:
                    st.info(
                        f'å½“å‰æ’å[{choice}]å·²ç»è¢«å¥å­[{rank_results.index(choice) + 1}]å ç”¨ï¼Œè¯·å…ˆå°†å ç”¨æ’åçš„å¥å­ç½®ä¸º-1å†ä¸ºå½“å‰å¥å­åˆ†é…è¯¥æ’åã€‚')
                else:
                    rank_results[i] = choice
                color = RANK_COLOR[i] if i < len(RANK_COLOR) else 'white'
                current_results = st.session_state.get('current_results', [])
                if i < len(current_results):
                    text = current_results[i]
                else:
                    text = ''

                st.markdown(f":{color}[{text}]")

    with st.expander('ğŸ¥‡ Rank Results', expanded=True):
        columns = st.columns([1] * MODEL_CONFIG['rank_list_len'])
        for i, c in enumerate(columns):
            with c:
                st.write(f'Rank {i+1}ï¼š')
                if i + 1 in rank_results:
                    color = RANK_COLOR[rank_results.index(i+1)] if rank_results.index(i+1) < len(RANK_COLOR) else 'white'
                    st.markdown(f":{color}[{st.session_state['current_results'][rank_results.index(i+1)]}]")

    # æ›¿æ¢é¡µé¢å®šä¹‰åŒºæ ‡æ³¨é¡µé¢ä¸­çš„æ•°æ®è¯»å–æ–¹å¼å’Œä¿å­˜æ–¹å¼
    save_button = st.button('å­˜å‚¨å½“å‰æ’åº')
    if save_button:
        if -1 in rank_results:
            st.error('è¯·å®Œæˆæ’åºåå†å­˜å‚¨ï¼', icon='ğŸš¨')
            st.stop()

        prompt_text = st.session_state['current_prompt']
        data = {"prompt": prompt_text}
        for i in range(len(rank_results)):
            data[f'rank_{i + 1}'] = st.session_state['current_results'][rank_results.index(i + 1)]
        save_to_json(data)

        st.success('ä¿å­˜æˆåŠŸï¼Œè¯·æ›´æ¢promptç”Ÿæˆæ–°çš„ç­”æ¡ˆ~', icon="âœ…")

######################### é¡µé¢å®šä¹‰åŒºï¼ˆæ•°æ®é›†é¡µé¢ï¼‰ #######################
# æ›¿æ¢é¡µé¢å®šä¹‰åŒºæ•°æ®é›†é¡µé¢ä¸­çš„æ•°æ®è¯»å–æ–¹å¼
with dataset_tab:
# è¯»å–æ•°æ®å¹¶åˆ›å»º DataFrame ç¤ºä¾‹
    rank_texts_list = read_from_json()
    df = pd.DataFrame(rank_texts_list)

    # åœ¨ Streamlit ç•Œé¢ä¸­æ˜¾ç¤ºå¯ç¼–è¾‘è¡¨æ ¼
    edited_df = st.data_editor(df)

# å¢åŠ ä¿å­˜æŒ‰é’®
    if st.button('ä¿å­˜æ›´æ”¹'):
        # å°†ç¼–è¾‘åçš„ DataFrame è½¬æ¢ä¸º list æ ¼å¼
        updated_data = edited_df.to_dict('records')

        with open(MODEL_CONFIG["dataset_file"], "w", encoding="utf-8") as f:
            for data in updated_data:
                json.dump(data, f, ensure_ascii=False)
                f.write("\n")

    st.success('ä¿å­˜æˆåŠŸï¼')

